{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN CNN RNN transformer等model，gan、reinforcement learning\n",
    "  函數學習機 --> 調參，起始值隨便挑\n",
    "grdient descent\n",
    "backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把要問的問題劃成函數\n",
    "訓練資料\n",
    "找出函數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 讀入套件\n",
    "這裡我們讀入一些套件, 今天暫時不要理會細節。\n",
    "\n",
    "再來是我們標準數據分析動作!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%env KERAS_BACKEND=tensorflow\n",
    "\n",
    "# 標準數據分析、畫圖套件\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 神經網路方面\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# 互動設計用\n",
    "from ipywidgets import interact_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 讀入 MNIST 數據庫\n",
    "MNIST 是有一堆 0-9 的手寫數字圖庫。有 6 萬筆訓練資料, 1 萬筆測試資料。它是 \"Modified\" 版的 NIST 數據庫, 原來的版本有更多資料。這個 Modified 的版本是由 LeCun, Cortes, 及 Burges 等人做的。可以參考這個數據庫的原始網頁。\n",
    "\n",
    "MNIST 可以說是 Deep Learning 最有名的範例, 它被 Deep Learning 大師 Hinton 稱為「機器學習的果蠅」。\n",
    "\n",
    "## 2.1 由 Keras 讀入 MNIST\n",
    "Keras 很貼心的幫我們準備好 MNIST 數據庫, 我們可以這樣讀進來 (第一次要花點時間)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們來看看訓練資料是不是 6 萬筆、測試資料是不是有 1 筆。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料總筆數為 60000 筆資料\n",
      "測試資料總筆數為 10000 筆資料\n"
     ]
    }
   ],
   "source": [
    "print(f'訓練資料總筆數為 {len(x_train)} 筆資料')\n",
    "print(f'測試資料總筆數為 {len(x_test)} 筆資料')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 數據庫的內容\n",
    "每筆輸入 (x) 就是一個手寫的 0-9 中一個數字的圖檔, 大小為 28x28。而輸出 (y) 當然就是「正確答案」。我們來看看編訓練資料的 x 輸入、輸出的部份分別長什麼樣子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_xy(n=0):\n",
    "    ax = plt.gca()\n",
    "    X = x_train[n]\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.imshow(X, cmap = 'Greys')\n",
    "    print(f'本資料 y 給定的答案為: {y_train[n]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff806b2f38d4461a506e02a1e4af4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='n', max=59999), Button(description='Run Interact', style=ButtonStyle()), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact_manual(show_xy, n=(0,59999));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 110\n",
    "X = x_train[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21,\n",
       "        133, 254, 254,  61,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,  81, 226,\n",
       "        253, 253, 253, 228,  44,  50,   7,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 149, 253, 253,\n",
       "        215, 111, 204, 253, 253, 253, 173,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 244, 253, 163,\n",
       "         14,   0,   9, 212, 253, 253, 173,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  82, 246, 253, 196,  19,\n",
       "          0,   0,   0, 183, 253, 253, 144,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  19, 246, 253, 198,  17,   0,\n",
       "          0,   1, 117, 250, 253, 253,  74,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  93, 253, 253,  69,   0,   0,\n",
       "          0,  78, 253, 253, 253, 253,  74,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 135, 253, 225,   4,   0,   0,\n",
       "         63, 245, 253, 222, 253, 250,  63,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 219, 253, 223,   0,  15, 132,\n",
       "        229, 252, 135,  25, 253, 228,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 122, 253, 253, 249, 250, 253,\n",
       "        204,  63,   0,  15, 253, 228,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40, 253, 253, 253, 253, 212,\n",
       "         22,   0,   0,  15, 253, 239,  31,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   8,  94, 184, 193, 138,  22,\n",
       "          0,   0,   0,  16, 253, 254,  74,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,  15, 253, 253,  74,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,  11, 230, 253, 102,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 169, 254, 173,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 169, 253, 173,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,  78, 254, 248,  32,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,  18, 232, 253, 120,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0, 128, 253, 215,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,  37, 185, 179,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 輸入格式整理\n",
    "我們現在要用標準神經網路學學手寫辨識。原來的每筆數據是個 28x28 的矩陣 (array), 但標準神經網路只吃「平平的」, 也就是每次要 28x28=784 長的向量。因此我們要用 reshape 調校一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28 * 28 = 784拉平\n",
    "x_train = x_train.reshape(60000, 784)/255\n",
    "x_test = x_test.reshape(10000, 784)/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 輸出格式整理\n",
    "我們可能會想, 我們想學的函數是這樣的型式:\n",
    "\n",
    "f̂ :ℝ784→ℝ\n",
    "其實這樣不太好! 為什麼呢? 比如說我們的輸入 x 是一張 0 的圖, 因為我們訓練的神經網路總會有點誤差, 所以可能會得到:\n",
    "\n",
    "f̂ (x)=0.5\n",
    "那這意思是有可能是 0, 也有可能是 1 嗎!!?? 可是 0 和 1 根本不像啊。換句話說分類的問題這樣做其實不合理!\n",
    "\n",
    "於是我們會做 \"1-hot enconding\", 也就是\n",
    "\n",
    "1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "5 -> [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
    "等等。因為分類問題基本上都要做這件事, Keras 其實已幫我們準備好套件!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們來看看剛剛某號數據的答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 87\n",
    "y_train[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和我們想的一樣! 至此我們可以打造我們的神經網路了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 打造第一個神經網路\n",
    "我們決定了我們的函數是\n",
    "\n",
    "f̂ :ℝ784→ℝ10\n",
    "這個樣子。而我們又說第一次要用標準神網路試試, 所以我們只需要再決定要幾個隱藏層、每層要幾個神經元, 用哪個激發函數就可以了。\n",
    "\n",
    "## 3.1 決定神經網路架構、讀入相關套件\n",
    "假如我們要這麼做:\n",
    "\n",
    "* 使用 3 個 hidden layers\n",
    "* Hidden layer 1 用 6 個神經元\n",
    "* Hidden layer 2 用 28 個神經元\n",
    "* Hidden layer 3 用 2 個神經元\n",
    "\n",
    "* Activation Function 唯一指名 relu\n",
    "\n",
    "於是從 Keras 把相關套件讀進來。\n",
    "\n",
    "## 3.2 建構我們的神經網路\n",
    "和以前做迴歸或機器學習一樣, 我們就打開個「函數學習機」。標準一層一層傳遞的神經網路叫 Sequential, 於是我們打開一個空的神經網路。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#開一個函數學習機\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們每次用 add 去加一層, 從第一個隱藏層開始。而第一個隱藏層因為 Keras 當然猜不到輸入有幾個 features, 所以我們要告訴它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一層，Dense全連集 ,28*28 = 784\n",
    "model.add(Dense(6, input_dim=784, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二層 hidden layer 因為前面輸出是 4, 現在輸入是 2, 就不用再說了! 這裡的 2 只告訴 Keras, 我們第二層是用 2 個神經元!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(28, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(2, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "輸出有 10 個數字, 所以輸出層的神經元是 10 個! 而如果我們的網路輸出是\n",
    "\n",
    "(y1,y2,…,y10)\n",
    "我們還希望\n",
    "\n",
    "∑i=110yi=1\n",
    "這可能嗎, 結果是很容易, 就用 softmax 當激發函數就可以!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax 加起來等於一\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此我們的第一個神經網路就建好了!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 組裝\n",
    "和之前比較不一樣的是我們還要做 compile 才正式把我們的神經網路建好。你可以發現我們還需要做幾件事:\n",
    "\n",
    "決定使用的 loss function, 一般是 mse\n",
    "決定 optimizer, 我們用標準的 SGD\n",
    "設 learning rate\n",
    "為了一邊訓練一邊看到結果, 我們加設\n",
    "\n",
    "metrics=['accuracy']\n",
    "\n",
    "本行基本上和我們的神經網路功能沒有什麼關係。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#平均的平方和 lr:learning rate\n",
    "model.compile(loss='mse', optimizer=SGD(lr=0.087), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 檢視我們的神經網路\n",
    "我們可以檢視我們神經網路的架構, 可以確認一下是不是和我們想像的一樣。\n",
    "\n",
    "## 4.1 看 model 的 summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 4710      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               1400      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 28)                5628      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 58        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                30        \n",
      "=================================================================\n",
      "Total params: 11,826\n",
      "Trainable params: 11,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# param一共用了幾個參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很快算算參數數目和我們想像是否是一樣的!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#全重數 + 偏執（每一個神經元都有一個偏執\n",
    "6*28 + 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 訓練你的第一個神經網路\n",
    "恭喜! 我們完成了第一個神經網路。現在要訓練的時候, 你會發現不是像以前沒頭沒腦把訓練資料送進去就好。這裡我們還有兩件事要決定:\n",
    "\n",
    "一次要訓練幾筆資料 (batch_size), 我們就 100 筆調一次參數好了\n",
    "這 6 萬筆資料一共要訓練幾次 (epochs), 我們訓練個 20 次試試\n",
    "於是最精彩的就來了。你要有等待的心理準備..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0900 - acc: 0.1111\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0900 - acc: 0.1124\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0898 - acc: 0.1124\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0894 - acc: 0.1124: 0s - loss: 0.0\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0886 - acc: 0.1336\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0871 - acc: 0.2090\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0835 - acc: 0.2564\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0814 - acc: 0.2614\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0806 - acc: 0.2639\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0799 - acc: 0.2681\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0785 - acc: 0.2736\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0754 - acc: 0.2909\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0735 - acc: 0.3011\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0728 - acc: 0.303 - 2s 27us/step - loss: 0.0728 - acc: 0.3034\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0724 - acc: 0.3049\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0722 - acc: 0.3061\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0720 - acc: 0.3070\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0718 - acc: 0.3078\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0717 - acc: 0.3086\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0716 - acc: 0.3089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1228bd208>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=100, epochs=20)\n",
    "#每一百次檢查一次  調整對答案 ,epochs訓練幾次"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 試用我們的結果\n",
    "我們來用比較炫的方式來看看可愛的神經網路學習成果。對指令有問題可以參考我們之前的 MOOC 影片教學。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們 \"predict\" 放的是我們神經網路的學習結果。這裡用 predict_classes 會讓我們 Keras 選 10 個輸出機率最大的那類。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6, 1, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不要忘了我們的 x_test 每筆資料已經換成 784 維的向量, 我們要整型回 28x28 的矩陣才能當成圖形顯示出來!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(測試編號):\n",
    "    plt.imshow(x_test[測試編號].reshape(28,28), cmap='Greys')\n",
    "    print('神經網路判斷為:', predict[測試編號])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "神經網路判斷為: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623289ea7e904c63b217ae33b7f0f346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=4999, description='測試編號', max=9999), Button(description='Run Interact', style=ButtonStyle()), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.test>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_manual(test, 測試編號=(0, 9999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到底測試資料總的狀況如何呢? 我們可以給我們神經網路「考一下試」。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 51us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.07115027158260345\n",
      "正確率 0.3122\n"
     ]
    }
   ],
   "source": [
    "print('loss:', score[0])\n",
    "print('正確率', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 訓練好的神經網路存起來!\n",
    "如果對訓練成果滿意, 我們當然不想每次都再訓練一次! 我們可以把神經網路的架構和訓練好的參數都存起來, 以供日後使用!\n",
    "\n",
    "之前還沒裝 pyh5 要在終端機 (Anaconda Prompt) 下安裝:\n",
    "\n",
    "conda install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`save_weights` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-b2c2baea7096>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stupid_model.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stupid_model_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`save_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m         \u001b[0;31m# If file exists and should not be overwritten:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: `save_weights` requires h5py."
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "open('stupid_model.json', 'w').write(model_json)\n",
    "model.save_weights('stupid_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
